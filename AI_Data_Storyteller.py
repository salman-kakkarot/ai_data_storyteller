{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1adddf2f-8805-42a2-980e-7ddf618bb8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_data_storyteller.py\n",
    "# Unified AI-Powered Data Storyteller\n",
    "# - CLI: python ai_data_storyteller.py <path_to_csv>\n",
    "# - Dashboard: streamlit run ai_data_storyteller.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from fpdf import FPDF\n",
    "from typing import Dict, Optional\n",
    "\n",
    "# Streamlit guarded import\n",
    "try:\n",
    "    import streamlit as st\n",
    "    STREAMLIT = True\n",
    "except Exception:\n",
    "    STREAMLIT = False\n",
    "\n",
    "# HuggingFace LLM support\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "    HF_AVAILABLE = True\n",
    "except Exception:\n",
    "    HF_AVAILABLE = False\n",
    "\n",
    "# OpenAI LLM support\n",
    "OPENAI_AVAILABLE = False\n",
    "try:\n",
    "    import openai\n",
    "    if os.getenv(\"OPENAI_API_KEY\"):\n",
    "        OPENAI_AVAILABLE = True\n",
    "except Exception:\n",
    "    OPENAI_AVAILABLE = False\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Dataset utilities\n",
    "# -------------------------\n",
    "def load_dataset(path: Optional[str] = None) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Try to load dataset from CLI path, default data.csv, or file picker (CLI only).\"\"\"\n",
    "    if path and os.path.exists(path):\n",
    "        return pd.read_csv(path)\n",
    "\n",
    "    if os.path.exists(\"data.csv\"):\n",
    "        return pd.read_csv(\"data.csv\")\n",
    "\n",
    "    if STREAMLIT:\n",
    "        return None  # handled by uploader\n",
    "\n",
    "    # fallback: file picker for CLI mode\n",
    "    try:\n",
    "        from tkinter import Tk\n",
    "        from tkinter.filedialog import askopenfilename\n",
    "        Tk().withdraw()\n",
    "        file_path = askopenfilename(filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "        if file_path:\n",
    "            print(f\"Loading dataset from: {file_path}\")\n",
    "            return pd.read_csv(file_path)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print(\"❌ No dataset found. Please:\")\n",
    "    print(\"  • Pass a path: python ai_data_storyteller.py yourdata.csv\")\n",
    "    print(\"  • Place a file named data.csv in this folder\")\n",
    "    print(\"  • Or (CLI only) select via file picker\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def validate_df(df: pd.DataFrame) -> Dict:\n",
    "    return {\n",
    "        \"shape\": df.shape,\n",
    "        \"columns\": df.columns.tolist(),\n",
    "        \"dtypes\": df.dtypes.apply(str).to_dict(),\n",
    "        \"missing\": df.isnull().sum().to_dict(),\n",
    "        \"too_many_nans\": [c for c, v in df.isnull().sum().items() if v / df.shape[0] > 0.5],\n",
    "    }\n",
    "\n",
    "\n",
    "def numeric_summary(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.select_dtypes(include=[np.number]).describe().T\n",
    "\n",
    "\n",
    "def categorical_summary(df: pd.DataFrame, top_n=10) -> Dict[str, pd.Series]:\n",
    "    return {\n",
    "        c: df[c].value_counts(dropna=False).head(top_n)\n",
    "        for c in df.select_dtypes(exclude=[np.number]).columns\n",
    "    }\n",
    "\n",
    "\n",
    "def correlation_matrix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    num = df.select_dtypes(include=[np.number])\n",
    "    return num.corr() if num.shape[1] >= 2 else pd.DataFrame()\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Plots\n",
    "# -------------------------\n",
    "def plot_histogram(df: pd.DataFrame, column: str):\n",
    "    return px.histogram(df, x=column, nbins=30, title=f\"Distribution: {column}\")\n",
    "\n",
    "\n",
    "def plot_bar_for_cat(df: pd.DataFrame, column: str):\n",
    "    vc = df[column].value_counts().reset_index().rename(columns={\"index\": column, column: \"count\"})\n",
    "    return px.bar(vc, x=column, y=\"count\", title=f\"Counts: {column}\")\n",
    "\n",
    "\n",
    "def plot_correlation_heatmap(df: pd.DataFrame):\n",
    "    corr = correlation_matrix(df)\n",
    "    return px.imshow(corr, text_auto=True, title=\"Correlation matrix\") if not corr.empty else None\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# LLM Insights\n",
    "# -------------------------\n",
    "def prepare_insight_prompt(df: pd.DataFrame, max_cats=5) -> str:\n",
    "    nrows, ncols = df.shape\n",
    "    parts = [f\"Dataset has {nrows} rows and {ncols} columns.\"]\n",
    "\n",
    "    num_summary = numeric_summary(df)\n",
    "    if not num_summary.empty:\n",
    "        parts.append(\"Numeric summary (first 6 numeric columns):\")\n",
    "        parts.append(num_summary.head(6).to_string())\n",
    "\n",
    "    corr = correlation_matrix(df)\n",
    "    if not corr.empty:\n",
    "        corr_abs = (\n",
    "            corr.abs()\n",
    "            .unstack()\n",
    "            .reset_index()\n",
    "            .rename(columns={0: \"corr\"})\n",
    "            .query(\"level_0 != level_1\")\n",
    "            .sort_values(\"corr\", ascending=False)\n",
    "            .head(5)\n",
    "        )\n",
    "        parts.append(\"Top correlations:\")\n",
    "        for _, r in corr_abs.iterrows():\n",
    "            parts.append(f\"{r['level_0']} vs {r['level_1']} = {r['corr']:.3f}\")\n",
    "\n",
    "    for c, vc in list(categorical_summary(df, top_n=max_cats).items())[:3]:\n",
    "        parts.append(f\"{c}: {vc.to_dict()}\")\n",
    "\n",
    "    parts.append(\"Task: Provide 6 insights + 1–2 data quality notes.\")\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "\n",
    "def load_hf_generator(model=\"google/flan-t5-small\"):\n",
    "    tok = AutoTokenizer.from_pretrained(model)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model)\n",
    "    return pipeline(\"text2text-generation\", model=model, tokenizer=tok)\n",
    "\n",
    "\n",
    "def generate_insights(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Generate natural language insights from dataset using HF or OpenAI.\"\"\"\n",
    "    prompt = prepare_insight_prompt(df)\n",
    "\n",
    "    if HF_AVAILABLE:\n",
    "        try:\n",
    "            gen = load_hf_generator()\n",
    "            return gen(prompt, max_length=256, do_sample=False)[0][\"generated_text\"]\n",
    "        except Exception as e:\n",
    "            return f\"[HuggingFace error] {e}\"\n",
    "\n",
    "    if OPENAI_AVAILABLE:\n",
    "        try:\n",
    "            resp = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{\"role\": \"system\", \"content\": \"You are a data analyst.\"},\n",
    "                          {\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=400,\n",
    "                temperature=0,\n",
    "            )\n",
    "            return resp[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except Exception as e:\n",
    "            return f\"[OpenAI error] {e}\"\n",
    "\n",
    "    return \"⚠️ No LLM available. Use this prompt manually:\\n\\n\" + prompt\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# PDF Report\n",
    "# -------------------------\n",
    "class PDFReport:\n",
    "    def __init__(self, title=\"Executive Summary\"):\n",
    "        self.pdf = FPDF()\n",
    "        self.pdf.set_auto_page_break(auto=True, margin=15)\n",
    "        self.title = title\n",
    "\n",
    "    def add_text(self, text: str):\n",
    "        self.pdf.add_page()\n",
    "        self.pdf.set_font(\"Arial\", \"B\", 16)\n",
    "        self.pdf.cell(0, 10, self.title, ln=True, align=\"C\")\n",
    "        self.pdf.ln(8)\n",
    "        self.pdf.set_font(\"Arial\", size=10)\n",
    "        self.pdf.multi_cell(0, 6, text)\n",
    "\n",
    "    def add_plot(self, fig, caption=\"\"):\n",
    "        if fig is None:\n",
    "            return\n",
    "        try:\n",
    "            img_bytes = fig.to_image(format=\"png\", width=700, height=400, scale=1)\n",
    "            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".png\")\n",
    "            tmp.write(img_bytes)\n",
    "            tmp.close()\n",
    "            self.pdf.image(tmp.name, w=180)\n",
    "            if caption:\n",
    "                self.pdf.ln(2)\n",
    "                self.pdf.multi_cell(0, 6, caption)\n",
    "            os.remove(tmp.name)\n",
    "        except Exception as e:\n",
    "            print(\"Plot export failed:\", e)\n",
    "\n",
    "    def save(self, path=\"executive_summary.pdf\") -> str:\n",
    "        self.pdf.output(path)\n",
    "        return path\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# CLI Mode\n",
    "# -------------------------\n",
    "def cli_mode(path=None):\n",
    "    df = load_dataset(path)\n",
    "    if df is None:\n",
    "        return\n",
    "\n",
    "    print(\"✅ Dataset loaded\")\n",
    "    print(\"Validation:\", validate_df(df))\n",
    "    print(\"\\nNumeric summary:\\n\", numeric_summary(df).head())\n",
    "\n",
    "    insights = generate_insights(df)\n",
    "    print(\"\\n--- Insights ---\\n\", insights)\n",
    "\n",
    "    report = PDFReport()\n",
    "    report.add_text(insights)\n",
    "\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "    if num_cols:\n",
    "        report.add_plot(plot_histogram(df, num_cols[0]), \"Histogram\")\n",
    "    if cat_cols:\n",
    "        report.add_plot(plot_bar_for_cat(df, cat_cols[0]), \"Bar chart\")\n",
    "    corr_fig = plot_correlation_heatmap(df)\n",
    "    if corr_fig is not None:\n",
    "        report.add_plot(corr_fig, \"Correlation heatmap\")\n",
    "\n",
    "    outpath = report.save()\n",
    "    print(f\"📄 Report saved: {outpath}\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Dashboard Mode\n",
    "# -------------------------\n",
    "def dashboard_mode():\n",
    "    st.title(\"AI Data Storyteller\")\n",
    "    st.write(\"Upload CSV → Auto EDA → Insights → PDF Report\")\n",
    "\n",
    "    uploaded = st.file_uploader(\"Upload CSV\", type=[\"csv\"])\n",
    "    if not uploaded:\n",
    "        st.info(\"⬆️ Please upload a CSV file to continue.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(uploaded)\n",
    "    except Exception as e:\n",
    "        st.error(f\"⚠️ Failed to read CSV: {e}\")\n",
    "        return\n",
    "\n",
    "    if df.empty:\n",
    "        st.error(\"⚠️ CSV file is empty.\")\n",
    "        return\n",
    "\n",
    "    st.write(\"### Preview\", df.head())\n",
    "    st.json(validate_df(df))\n",
    "    st.dataframe(numeric_summary(df))\n",
    "\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "    if num_cols:\n",
    "        st.plotly_chart(plot_histogram(df, num_cols[0]))\n",
    "    if cat_cols:\n",
    "        st.plotly_chart(plot_bar_for_cat(df, cat_cols[0]))\n",
    "    corr_fig = plot_correlation_heatmap(df)\n",
    "    if corr_fig is not None:\n",
    "        st.plotly_chart(corr_fig)\n",
    "\n",
    "    insights = generate_insights(df)\n",
    "    st.text_area(\"Insights\", insights, height=200)\n",
    "\n",
    "    if st.button(\"Download PDF\"):\n",
    "        report = PDFReport()\n",
    "        report.add_text(insights)\n",
    "        if num_cols:\n",
    "            report.add_plot(plot_histogram(df, num_cols[0]), \"Histogram\")\n",
    "        if cat_cols:\n",
    "            report.add_plot(plot_bar_for_cat(df, cat_cols[0]), \"Bar chart\")\n",
    "        if corr_fig is not None:\n",
    "            report.add_plot(corr_fig, \"Correlation heatmap\")\n",
    "\n",
    "        path = report.save(\"executive_summary_dashboard.pdf\")\n",
    "        with open(path, \"rb\") as f:\n",
    "            b64 = base64.b64encode(f.read()).decode()\n",
    "        st.markdown(\n",
    "            f'<a href=\"data:file/pdf;base64,{b64}\" download=\"executive_summary.pdf\">📥 Download Report</a>',\n",
    "            unsafe_allow_html=True,\n",
    "        )\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Entry Point\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    if STREAMLIT and any(\"streamlit\" in arg for arg in sys.argv):\n",
    "        dashboard_mode()\n",
    "    else:\n",
    "        path = sys.argv[1] if len(sys.argv) > 1 else None\n",
    "        cli_mode(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "d28fe92f-dba9-4e22-954e-6cab6c464ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": None,
   "id": "2e41338b-8e3e-4222-8d8f-64771b6b92cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
